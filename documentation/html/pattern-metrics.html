<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
    <title>pattern-metrics</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <link type="text/css" rel="stylesheet" href="../clips.css" />
    <style>
        /* Small fixes because we omit the online layout.css. */
        h3 { line-height: 1.3em; }
        #page { margin-left: auto; margin-right: auto; }
        #header, #header-inner { height: 175px; }
        #header { border-bottom: 1px solid #C6D4DD;  }
        table { border-collapse: collapse; }
    </style>
    <link href="../js/shCore.css" rel="stylesheet" type="text/css" />
    <link href="../js/shThemeDefault.css" rel="stylesheet" type="text/css" />
    <script language="javascript" src="../js/shCore.js"></script>
    <script language="javascript" src="../js/shBrushXml.js"></script>
    <script language="javascript" src="../js/shBrushJScript.js"></script>
    <script language="javascript" src="../js/shBrushPython.js"></script>
</head>
<body class="node-type-page one-sidebar sidebar-right section-pages">
    <div id="page">
    <div id="page-inner">
    <div id="header"><div id="header-inner"></div></div>
    <div id="content">
    <div id="content-inner">
    <div class="node node-type-page"
        <div class="node-inner">
        <div class="breadcrumb">View online at: <a href="http://www.clips.ua.ac.be/pages/pattern-metrics" class="noexternal" target="_blank">http://www.clips.ua.ac.be/pages/pattern-metrics</a></div>
        <h1>pattern.metrics</h1>
        <!-- Parsed from the online documentation. -->
        <div id="node-1405" class="node node-type-page"><div class="node-inner">
<div class="content">
<p><span class="big">The pattern.metrics module is a loose collection of performance and accuracy measurements, including tools for profiling the speed of Python functions, precision and recall for classifiers, agreement across different voters (Fleiss), string similarity (Levenshtein + Dice), string readability (Flesch), descriptive statistics.</span></p>
<p>It can be used by itself or with other&nbsp;<a href="pattern.html">pattern</a>&nbsp;modules:&nbsp;<a href="pattern-web.html">web</a>&nbsp;|&nbsp;<a href="pattern-db.html">db</a>&nbsp;|&nbsp;<a href="pattern-en.html">en</a>&nbsp;|&nbsp;<a href="pattern-search.html">search</a>&nbsp;<span class="blue">&nbsp;</span>| <a href="pattern-vector.html">vector</a> |&nbsp;<a href="pattern-graph.html">graph</a>.</p>
<p><img src="../g/pattern_schema.gif" alt="" width="620" height="180" /></p>
<hr />
<h2>Documentation</h2>
<ul>
<li><a href="#profile">Profiler</a></li>
<li><a href="#accuracy">Accuracy, precision and recall</a></li>
<li><a href="#agreement">Agreement</a></li>
<li><a href="#similarity">String similarity</a></li>
<li><a href="#readability">String readability</a></li>
<li><a href="#intertextuality">Intertextuality</a></li>
<li><a href="#statistics">Statistics</a><span class="link-maintenance small"> (mean, histogram, quantile, ...)</span></li>
</ul>
<p>&nbsp;</p>
<hr />
<h2><a name="profile"></a>Profiler</h2>
<p>In general, Python is highly optimized with C extensions (e.g., string manipulation, dictionary access, regular expressions). The Pattern module is optimized with a number of caching mechanisms.&nbsp;To test if your own code is fast or slow you need to profile it. You can then optimize the slowest parts, typically the three slowest functions.&nbsp;You should do this&nbsp;<em>after</em>&nbsp;all the code has been written, since you can only measure speed if the program first gives the correct results.</p>
<p><span class="inline_code">duration()</span> takes a function + its (optional) arguments and returns the running time in seconds.</p>
<p><span class="inline_code">profile()&nbsp;</span>takes a function and returns a string of performance statistics for the top 20 slowest parts.</p>
<pre class="brush:python; gutter:false; light:true;">duration(function, *args, **kwargs)</pre><pre class="brush:python; gutter:false; light:true;">profile(function, *args, **kwargs)</pre><div class="example">
<pre class="brush:python; gutter:false; light:true;">&gt;&gt;&gt; from pattern.metrics import profile
&gt;&gt;&gt; from pattern.en import parse, Sentence
&gt;&gt;&gt; def main():
&gt;&gt;&gt;     for i in range(100):
&gt;&gt;&gt;         s = Sentence(parse(&quot;the cat sat on the mat&quot;))
&gt;&gt;&gt;
&gt;&gt;&gt; print profile(main)</pre></div>
<p>&nbsp;</p>
<hr />
<h2><a name="accuracy"></a>Accuracy, precision and recall</h2>
<p>Say you have an&nbsp;<span class="inline_code">is_spam()</span> algorithm that yields&nbsp;<span class="inline_code">True</span> or <span class="inline_code">False</span>. You test it with a 1,000 e-mail messages of which 200 are spam. Say it identifies 180 messages as spam. The accuracy is 90% (180/200). But what does this really mean? The algorithm may have tagged 180 <em>good</em> e-mails as spam (= false positives) and 180 <em>bad</em> e-mails as ham (= false negatives).&nbsp;No real harm is done in terms of&nbsp;<span class="inline_code">is_spam()</span>, but a&nbsp;<span class="inline_code">has_cancer()</span> algorithm is an entirely different matter. Care has to be taken when evaluating the quality of predictive algorithms.&nbsp;</p>
<p>Precision and recall are measurements based on the actual amount of true positives â€“ e.g., where <span class="inline_code">is_spam()</span> yields&nbsp;<span class="inline_code">True</span> for e-mails that <em>really are</em> spam.</p>
<ul>
<li><strong>precision:</strong> how well messages that are not spam are discarded (= rule out false positives).&nbsp;</li>
<li><strong>recall:</strong> how well possible spam messages are selected (= rule out false negatives).</li>
</ul>
<p><span class="inline_code">confusion_matrix()</span>&nbsp;takes a function&nbsp;that returns&nbsp;<span class="inline_code">True</span> or <span class="inline_code">False</span> for a given document (e.g., a string), and a list (<span class="inline_code">document</span>, <span class="inline_code">bool</span>)-tuples for testing; where <span class="inline_code">bool=True</span> marks documents that should be selected by your function. It&nbsp;returns a (<span class="inline_code">TP</span>, <span class="inline_code">TN</span>, <span class="inline_code">FP</span>, <span class="inline_code">FN</span>)-tuple with the amount of true positives, true negatives, false positives and false negatives.</p>
<p><span class="inline_code">test()</span>&nbsp;takes a&nbsp;function and a list of (<span class="inline_code">document</span>,&nbsp;<span class="inline_code">bool</span>)-tuples and returns a tuple with (<span class="inline_code">accuracy</span>,&nbsp;<span class="inline_code">precision</span>,&nbsp;<span class="inline_code">recall</span>,&nbsp;<span class="inline_code">F1-score</span>), based on the confusion matrix.</p>
<pre class="brush:python; gutter:false; light:true;">confusion_matrix(match=lambda document:False, documents=[(None,False)])</pre><pre class="brush:python; gutter:false; light:true;">test(match=lambda document:False, documents=[])</pre><table class="border">
<tbody>
<tr>
<td><span class="smallcaps">Metric</span></td>
<td><span class="smallcaps">Definition</span></td>
<td><span class="smallcaps">Description</span></td>
</tr>
<tr>
<td>accuracy</td>
<td><span class="inline_code">A = TP+TN / (TP+TN+FP+FN)</span></td>
<td>percentage of correct classifications</td>
</tr>
<tr>
<td>precision</td>
<td><span class="inline_code">P = TP / (TP+FP)</span></td>
<td>percentage of correct positive classifications</td>
</tr>
<tr>
<td>recall</td>
<td><span class="inline_code">R = TP / (TP+FN)</span></td>
<td>percentage of positive cases correctly classified as positive</td>
</tr>
<tr>
<td>F1-score</td>
<td><span class="inline_code">F = 2*P*R / (P+R)</span></td>
<td>harmonic mean of precision and recall</td>
</tr>
</tbody>
</table>
<p>For example:</p>
<div class="example">
<pre class="brush:python; gutter:false; light:true;">&gt;&gt;&gt; from pattern.metrics import confusion_matrix, test
&gt;&gt;&gt;
&gt;&gt;&gt; def is_spam(string):
&gt;&gt;&gt;     words = (w.strip(&#39;,.?!&quot;&#39;) for w in string.lower().split(&#39; &#39;))
&gt;&gt;&gt;     return len([w for w in words if w in (&#39;lottery&#39;, &#39;viagra&#39;)]) &gt; 0
&gt;&gt;&gt;
&gt;&gt;&gt; documents = [
&gt;&gt;&gt;     (&#39;Want to go for coffee?&#39;, False),
&gt;&gt;&gt;     (&#39;In attachment is the latest report.&#39;, False),
&gt;&gt;&gt;     (&#39;Here is the website I was talking about.&#39;, False),
&gt;&gt;&gt;     (&#39;We can improve our classifier by excluding &quot;Viagra&quot;.&#39;, False),
&gt;&gt;&gt;     (&#39;Buy Viagra online!&#39;, True),
&gt;&gt;&gt;     (&#39;Your e-mail address was selected in our lottery!&#39;, True)
&gt;&gt;&gt; ]
&gt;&gt;&gt; print confusion_matrix(is_spam, documents) 
&gt;&gt;&gt; print test(is_spam, documents)
 
(2, 3, 1, 0)
(0.83, 0.67, 1.00, 0.80) </pre></div>
<p>In this example, <span class="inline_code">is_spam()</span> correctly classifies 5 out of 6 messages (83% accuracy). It identifies all spam messages (100% recall), which is good. However, it also promotes a<em>&nbsp;</em>message that is not spam to the junk folder, which is bad. Only 2 out of 3 messages tagged as spam are in reality spam (67% precision). Here is room for improvement. Notice how there is a trade-off between recall (no spam in inbox) and precision (real e-mails in junk folder).</p>
<p>The following helper functions simply call <span class="inline_code">test()</span> internally and return a single metric:</p>
<pre class="brush:python; gutter:false; light:true;">accuracy(match=lambda document:False, documents=[])</pre><pre class="brush:python; gutter:false; light:true;">precision(match=lambda document:False, documents=[])</pre><pre class="brush:python; gutter:false; light:true;">recall(match=lambda document:False, documents=[])</pre><pre class="brush:python; gutter:false; light:true;">F1(match=lambda document:False, documents=[])</pre><pre class="brush:python; gutter:false; light:true;">F(match=lambda document:False, documents=[], beta=1)</pre><p>&nbsp;</p>
<hr />
<h2><a name="agreement"></a>Agreement</h2>
<p>Fleiss' kappa agreement measures reliability or consensus in ratings given by different voters. Say you and a colleague are writing an <span class="inline_code">is_subjective()</span> algorithm to detect opinions, sentiments, customer feedback, etc. It uses a list of adjectives (e.g., fantastic, disappointing) tagged&nbsp;with values between 0.0-1.0 (subjectivity). To avoid bias, you both&nbsp;tag the list and take the average of the two values for each adjective.&nbsp;However, say that each word you tagged 0.0 your colleague tagged 1.0. This results in low agreement, indicating that the function won't work properly because you didn't reach a consensus of what is subjective and what is not.</p>
<p><span class="inline_code">agreement()</span> returns the reliability as a number between -1.0 and +1.0 (where <span class="inline_code">+0.7</span> is reliable). The given <span class="inline_code">matrix</span> is a list in which each row represents a task. Each task is a list with the number of votes per category. Each column represents a category.</p>
<pre class="brush:python; gutter:false; light:true;">agreement(matrix)</pre><div class="example">
<pre class="brush:python; gutter:false; light:true;">&gt;&gt;&gt; m = [ # 0.0 0.5 1.0 SUBJ
&gt;&gt;&gt;       [  1,  1,  0  ], # important
&gt;&gt;&gt;       [  0   0,  2  ], # fantastic
&gt;&gt;&gt;       [  0,  1,  1  ], # disappointing
&gt;&gt;&gt;       [  2,  0,  0  ], # scientific
&gt;&gt;&gt; ]
&gt;&gt;&gt; from pattern.metrics import agreement
&gt;&gt;&gt; print agreement(m)

0.24 </pre></div>
<p>&nbsp;</p>
<hr />
<h2><a name="similarity"></a>String similarity</h2>
<p>Levenshtein edit distance measures the difference between two strings, as the number of operations (insert, delete, replace) required to transform one string into the other. Another similarity measure is Dice's coefficient, based on the number of shared bigrams â€“ e.g., <em>night</em> and <em>nacht</em> have one common bigram <em>ht</em>.</p>
<p><span class="inline_code">similarity()</span> returns the similarity of <span class="inline_code">string1</span> and <span class="inline_code">string2</span> as a number between <span class="inline_code">0.0</span> and <span class="inline_code">1.0</span>.<br />The given <span class="inline_code">metric</span> can be <span class="inline_code">LEVENSHTEIN</span> or <span class="inline_code">DICE</span>.&nbsp;</p>
<pre class="brush:python; gutter:false; light:true;">levenshtein(string1, string2) # Returns the edit distance.</pre><pre class="brush:python; gutter:false; light:true;">similarity(string1, string2, metric=LEVENSHTEIN)</pre><p>&nbsp;</p>
<hr />
<h2><a name="readability"></a>String readability</h2>
<p>Flesch reading ease measures the readability of a string based on word count and word length (number of syllables). The <span class="inline_code">readability()</span> function returns the readability as a number between <span class="inline_code">0.0</span> and <span class="inline_code">1.0</span>:</p>
<pre class="brush:python; gutter:false; light:true;">readibility(string)</pre><table class="border">
<tbody>
<tr>
<td><span class="smallcaps">Readability</span></td>
<td><span class="smallcaps">Description</span></td>
</tr>
<tr>
<td><span class="inline_code">0.9-1.0</span></td>
<td>easily understandable by 11-year olds</td>
</tr>
<tr>
<td><span class="inline_code">0.6-0.7</span></td>
<td>easily understandable by 13- to 15-year olds</td>
</tr>
<tr>
<td><span class="inline_code">0.3-0.5</span></td>
<td>best understood by university graduates</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<hr />
<h2><a name="intertextuality"></a>Intertextuality</h2>
<p>Intertextuality measures overlap between texts. For example, it can be used for plagiarism detection. The <span class="inline_code">intertextuality()</span> function returns a dictionary of&nbsp;<span class="inline_code">(i,</span> <span class="inline_code">j)</span> keys and <span class="inline_code">float</span> values. For indices <span class="inline_code">i</span> and <span class="inline_code">j</span> in the given list of texts (strings), the corresponding <span class="inline_code">float</span> is the percentage of text <span class="inline_code">i</span> that is also in text <span class="inline_code">j</span>. Overlap is measured by matching <em>n</em>-grams (by default, <span class="inline_code">n=5</span>&nbsp;or five successive words). An optional <span class="inline_code">weight</span> function can be used to supply the weight of each <em>n</em>-gram (by default <span class="inline_code">1</span>; but it can be useful to determine the weight of each <em>n</em>-gram using <a href="pattern-vector.html#tf-idf">TF-IDF</a>. An optional <span class="inline_code">continuous</span> parameter determines whether n-grams run over sentence periods.</p>
<pre class="brush: python;gutter: false; light: true; fontsize: 100; first-line: 1; ">texts=[], n=5, continuous=False, weight=lambda ngram: 1)</pre><div class="example">
<pre class="brush: python;gutter: false; light: true; fontsize: 100; first-line: 1; ">&gt;&gt;&gt; from pattern.metrics import intertextuality
&gt;&gt;&gt; from glob import glob
&gt;&gt;&gt; 
&gt;&gt;&gt; index = {} 
&gt;&gt;&gt; texts = []
&gt;&gt;&gt; for i, f in enumerate(glob(&#39;data/*.txt&#39;)):
&gt;&gt;&gt;     index[i] = f 
&gt;&gt;&gt;     texts.append(open(f).read())
&gt;&gt;&gt; 
&gt;&gt;&gt; for (i, j), weight in intertextuality(texts, n=3).items():
&gt;&gt;&gt;     if weight &gt; 0.1: 
&gt;&gt;&gt;         print index[i]
&gt;&gt;&gt;         print index[j]  
&gt;&gt;&gt;         print weight
&gt;&gt;&gt;         print weight.assessments # Set of overlapping n-grams.
&gt;&gt;&gt;         print </pre></div>
<p>&nbsp;</p>
<hr />
<h2><a name="statistics"></a>Statistics</h2>
<p>In mathematics, an&nbsp;<em>average</em> is a measure of the "middle" of a data set (or <em>sample</em>, usually a list of numbers). An average can be calculated in different ways, but commonly the&nbsp;<em>mean</em> is used. The arithmetic mean is the sum of the values divided by the sample size: [<span class="inline_code">1,2,4] â†’ 1+2+4 / 3 = 2.3</span>.&nbsp;Another average measure is the <em>median</em>, found by sorting the values from lowest to highest value and picking the middle one: <span class="inline_code">[1,2,4] â†’ 2</span>.&nbsp;</p>
<p>The <em>standard deviation</em> measures the amount of variation in a sample. Low standard deviation means the values tend to be close to the mean. If you draw it, you get a steep, narrow curve. High standard deviation means the values are spread out over a large range. If you draw it you get a flat, wide curve.</p>
<pre class="brush:python; gutter:false; light:true;">mean(list)                    # [1, 2, 4] =&gt; 2.33</pre><pre class="brush:python; gutter:false; light:true;">median(list)                  # [1, 2, 4] =&gt; 2</pre><pre class="brush:python; gutter:false; light:true;">variance(list, sample=True)   # Use sample=False for population variance.</pre><pre class="brush:python; gutter:false; light:true;">stdev(list)                   # [1, 2, 4] =&gt; 1.53</pre><p><span class="smallcaps"><br />Histogram</span></p>
<p>A <em>histogram</em> divides a list of numbers into intervals. This gives an idea of the distribution of the data: which interval has the most values? Are there more values in lower intervals? The <span class="inline_code">histogram()</span> function returns a dictionary with <span class="inline_code">k</span> items: <span class="inline_code">{(start, stop): [values], ...}</span>, with equal <span class="inline_code">(start, stop)</span> intervals between <span class="inline_code">min(list)</span> and <span class="inline_code">max(list)</span>.</p>
<pre class="brush:python; gutter:false; light:true;">histogram(list, k=10, range=None)</pre><div class="example">
<pre class="brush:python; gutter:false; light:true;">&gt;&gt;&gt; s = [1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9]
&gt;&gt;&gt; for (i,j), values in sorted(histogram(s, k=4).items()):
&gt;&gt;&gt;     m = i + (j-i)/2 # midpoint
&gt;&gt;&gt;     print i, j, m, values

1.0 3.0 2.0 [1, 1, 1, 1, 2, 2, 2, 3, 3]
3.0 5.0 4.0 [4, 5]
5.0 7.0 6.0 [6, 7]
7.0 9.0 8.0 [8, 9] </pre></div>
<p><span class="smallcaps"><br />Moment</span></p>
<p>A <em>moment</em> is a measure of the "shape" of a list of numbers. For example, the 2nd moment (which is the <em>variance</em>) measures the width.&nbsp;The 3rd moment measures&nbsp;<em>skewness</em>&nbsp;or asymmetry of the sample. If &gt; 0.0, relatively few values are higher than the mean. If &lt; 0.0, relatively few values are lower than the mean.&nbsp;The 4th moment measures&nbsp;<em>kurtosis</em> or peakedness of the sample. If &gt; 0.0, there is a sharp peak around the mean (more infrequent / extreme values). If &lt; 0.0 there is a wide peak around the mean.</p>
<pre class="brush:python; gutter:false; light:true;">moment(list, k=1)</pre><pre class="brush:python; gutter:false; light:true;">skewness(list)</pre><pre class="brush:python; gutter:false; light:true;">kurtosis(list)</pre><p><span class="smallcaps"><br />Quantile</span></p>
<p>The <span class="inline_code">quantile()</span> function returns the interpolated value from a sorted list of numbers at point <span class="inline_code">p</span> (0.0-1.0). The optional parameters <span class="inline_code">a</span>, <span class="inline_code">b</span>, <span class="inline_code">c</span>, <span class="inline_code">d</span> refer to the algorithm by Hyndman and Fan <a href="http://stat.ethz.ch/R-manual/R-patched/library/stats/html/quantile.html" target="_blank">[1]</a>. Quantiles can be used to create&nbsp;a <em>box plot</em>, useful for identifying&nbsp;<em>outliers</em>.&nbsp;For example: if a sample of temperature in your household comprises you (37Â°C), the cat (38Â°C),&nbsp;the refrigerator (5Â°C) and the oven (220Â°C) then the average temperature is 75Â°C, which of course is incorrect since the oven is an outlier.&nbsp;The <span class="inline_code">boxplot()</span>&nbsp;function returns a <span class="inline_code">(min, Q1, Q2, Q3, max)</span>-tuple for a given list of numbers, where <span class="inline_code">Q2</span> is the median, <span class="inline_code">Q1</span> is the lower 25-50% and <span class="inline_code">Q3</span> is the upper 50-75%.</p>
<pre class="brush:python; gutter:false; light:true;">quantile(list, p=0.5, sort=True, a=1, b=-1, c=0, d=1)</pre><pre class="brush:python; gutter:false; light:true;">boxplot(list)</pre><div class="example">
<pre class="brush:python; gutter:false; light:true;">&gt;&gt;&gt; s = [5, 37, 38, 220)
&gt;&gt;&gt; print boxplot(s)

(5.0, 29.0, 37.5,  83.5, 220.0)</pre></div>
<table class="border">
<tbody>
<tr>
<td style="text-align: center;"><img style="display: block; margin-left: auto; margin-right: auto;" src="../g/pattern-metrics-boxplot.jpg" alt="" width="398" height="137" /><span class="smallcaps">you, the cat, the fridge and the oven</span></td>
</tr>
</tbody>
</table>
<p><span class="small"><span style="text-decoration: underline;">Reference</span>: Adorio E. (2008)&nbsp;http://adorio-research.org/wordpress/?p=125</span></p>
<p>&nbsp;</p>
<hr />
<h2>Statistical tests&nbsp;</h2>
<p>A statistical hypothesis test is a method used to verify if sample data is evenly distributed (= the <em>null hypothesis</em>). For example: 96 subjects were asked about their pet. 29/46 men reported owning a dog, while 30/50 women reported owning a cat (fictious). Is gender correlated to pet ownership, in other words should we reject the null hypothesis?</p>
<p><span class="smallcaps">&nbsp;<br />Fisher's exact test</span></p>
<p>The <span class="inline_code">fisher_test()</span> function is a fast implementation of Fisher's exact test (two-tailed), using the hypergeometric distribution. It returns significance <span class="inline_code">P</span> for the 2 x 2 contingency table, where <span class="inline_code">P</span> <span class="inline_code">&lt;</span> <span class="inline_code">0.05</span>&nbsp;is significant and&nbsp;<span class="inline_code">P</span> <span class="inline_code">&lt;</span> <span class="inline_code">0.01</span>&nbsp;is very significant.</p>
<pre class="brush: python;gutter: false; light: true; fontsize: 100; first-line: 1; ">fisher_test(a, b, c, d)</pre><div class="example">
<pre class="brush: python;gutter: false; light: true; fontsize: 100; first-line: 1; ">&gt;&gt;&gt; print fisher_test(a=17, b=30, c=29, d=20)

0.027</pre></div>
<p>Suppose the data represents pet ownership:</p>
<table class="border" style="width: 50%;">
<tbody>
<tr>
<td>&nbsp;</td>
<td class="smallcaps" style="text-align: center;">Men</td>
<td class="smallcaps" style="text-align: center;">Women</td>
</tr>
<tr>
<td class="smallcaps" style="text-align: right;">cat owner</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">30</td>
</tr>
<tr>
<td class="smallcaps" style="text-align: right;">dog owner</td>
<td style="text-align: center;">29</td>
<td style="text-align: center;">20</td>
</tr>
</tbody>
</table>
<p>Since <span class="inline_code">P=0.027</span>&nbsp;<span class="inline_code">&lt;</span> <span class="inline_code">0.05</span>, the test shows a significant correlation between gender and pet ownership.</p>
<p><span class="smallcaps">&nbsp;<br />Chi-squared test</span></p>
<p>The <span class="inline_code">chi2()</span> function is a fast implementation of Pearson's chi-squared test. It returns an<span class="inline_code"> (X2, P)</span>-tuple for the <span class="inline_code">n</span> x <span class="inline_code">m</span> observed and expected data (containing absolute frequencies). Likewise, the <span class="inline_code">llr()</span> function returns the log-likelihood ratio as a <span class="inline_code">(G, P)</span>-tuple. With <span class="inline_code">expected=None</span>, an even distribution over all classes is assumed. If <span class="inline_code">df=None</span>, it is the number of classes-1 (i.e., <span class="inline_code">len(observed)[0] - 1</span>).</p>
<pre class="brush: python;gutter: false; light: true; fontsize: 100; first-line: 1; ">chi2(observed=[], expected=[], df=None, tail=UPPER) # UPPER | LOWER</pre><pre class="brush: python;gutter: false; light: true; fontsize: 100; first-line: 1; ">llr(observed=[], expected=[], df=None, tail=UPPER)  # UPPER | LOWER</pre><div class="example">
<pre class="brush: python;gutter: false; light: true; fontsize: 100; first-line: 1; ">&gt;&gt;&gt; observed = [[22, 21, 22, 27, 22, 36]]
&gt;&gt;&gt; expected = [[25, 25, 25, 25, 25, 25]] # Even distribution.
&gt;&gt;&gt; print chi2(observed, expected)

(6.72, 0.24)</pre></div>
<p>Suppose the data represents die rolls:</p>
<table class="border" style="width: 50%;">
<tbody>
<tr>
<td>&nbsp;</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
</tr>
<tr>
<td class="smallcaps">Die rolls</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">27</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">36</td>
</tr>
</tbody>
</table>
<p>Intuitively, the die appears to roll 6 more often.&nbsp;But&nbsp;<span class="inline_code">P=0.24</span> <span class="inline_code">&gt;</span> <span class="inline_code">0.05</span> is not significant, so there is no reason to reject the null hypothesis that the die is fair.</p>
</div>
</div></div>
        </div>
    </div>
    </div>
    </div>
    </div>
    </div>
    <script>
        SyntaxHighlighter.all();
    </script>
</body>
</html>